
--
-- Copyright (C) Analytics Engines
-- 2021 Alastair McKinley (a.mckinley@analyticsengines.com)
--

do $$
begin
    create type doc_format as enum ('xml','json','html');
    exception when duplicate_object then null;
end $$;

create table if not exists public_api.document_type (
    id bigint generated by default as identity primary key,
    name text not null unique,
    format doc_format not null,
    json_schema jsonb,
    document_validation_function text,
    pk_function text not null,
    xml_ns text[],
    created_on timestamp not null default now()
);

comment on table public_api.document_type is 'Defines the name, format (xml/json/html) and optional json schema, for a document type (e.g. legislation.gov.uk)';

create extension btree_gist;

create table if not exists public_api.document (
    id bigint generated by default as identity primary key,
    document_type_id bigint not null,
    pk text not null,
    latest boolean not null default true,
    revision_number int not null default 0,
    raw_text text not null,
    file_name text,
    _hash text not null unique, -- generated always as (hashtextextended(raw_text,2048)) stored,
    created_on timestamp not null default now(),
    user_id bigint default nullif(current_setting('request.jwt.claim.user_id',true),'')::bigint,
    foreign key (document_type_id) references public_api.document_type(id) on update cascade on delete cascade,
    foreign key (user_id) references users(id) on update cascade on delete cascade,
    constraint one_latest exclude using gist(pk with =,document_type_id with =,(nullif(latest,false)::int) with =) deferrable initially deferred,
    constraint latest_update_fk unique(id,latest),
    constraint unique_revision unique(pk,document_type_id,revision_number)
);

create index on public_api.document(pk);
create index on public_api.document(pk,document_type_id);

comment on table public_api.document is 'The core document storage model, immutable, either json or xml data';

grant select on public_api.document to orp_postgrest_web;
grant select on public_api.document_type to orp_postgrest_web;


-- create extension "postgres-json-schema";

create extension if not exists plpython3u;

do $$
begin
    create type validation_response as (
        ok boolean,
        errors text
    );
    exception when duplicate_object then null;
end $$;

create or replace function validate_jsonschema(schema jsonb,data jsonb) returns validation_response as
$$
    import jsonschema
    import json
    try:
        jsonschema.validate(json.loads(data),json.loads(schema))
        return [True,'']
    except jsonschema.exceptions.ValidationError as e:
        plpy.warning(f'jsonschema validation error - {e}')
        return [False,str(e)]
$$ language plpython3u;

select register_event_type(
    'new_document_revision',
    '{document_pk,document_revision}'::text[]
);

create or replace function document_before_insert_trigger_f() returns trigger as
$$
declare
dt public_api.document_type;
vr validation_response;
valid boolean;
pk_q text;
current_rev int;
begin
    select * into dt from public_api.document_type where id = new.document_type_id;
    select format('select %1$I(%2$L,%3$L)',dt.pk_function,new.raw_text,dt) into pk_q;
    execute pk_q into new.pk;

    select revision_number into current_rev from public_api.document where pk = new.pk and document_type_id = new.document_type_id;

    if current_rev is not null then
        select (current_rev + 1) into new.revision_number;
    end if;

    select hashtextextended(new.raw_text,2048) into new._hash;

    if (dt.format::text = 'json' and dt.json_schema is not null) then
        raise notice 'expecting a schema here';
        select vj.* into vr from validate_jsonschema(dt.json_schema,new.raw_text::jsonb) vj;
        if not vr.ok then
            raise data_exception using message = format('invalid json schema for document type %s with data %s errors %s',(select name from public_api.document_type where id = new.document_type_id),left(new.raw_text,100),vr.errors);
        end if;
    elsif (dt.format::text = 'xml') then
        if not xml_is_well_formed_document(new.raw_text) then
            raise data_exception using message = format('document type %s data %s is not valid xml',(select name from public_api.document_type where id = new.document_type_id),left(new.raw_text,100));
        end if;
        if dt.document_validation_function is not null then
            execute format('select %I(%L)',dt.document_validation_function,new.raw_text) into valid;
            if not valid then
                raise data_exception using message = format('document type %s data %s failed validation with function %I',(select name from public_api.document_type where id = new.document_type_id),left(new.raw_text,100),dt.document_validation_function);
            end if;
        end if;
    end if;
    return new;
end;
$$ language plpgsql;

drop trigger if exists before_insert_trigger on public_api.document;
create trigger before_insert_trigger before insert on public_api.document
for each row
execute procedure document_before_insert_trigger_f();



create or replace function document_after_insert_trigger_f() returns trigger as
$$
begin
    if new.revision_number > 0 then
        perform publish_event('new_document_revision',jsonb_build_object('document_pk',new.pk,'document_revision',new.revision_number));
    end if;

    update public_api.document d set latest = false where d.pk = new.pk and document_type_id = new.document_type_id and new._hash != d._hash;

    return new;
end;
$$ language plpgsql;

drop trigger if exists after_insert_trigger on public_api.document;
create trigger after_insert_trigger after insert on public_api.document
for each row
execute procedure document_after_insert_trigger_f();


create or replace function document_before_delete_trigger_f() returns trigger as
$$
declare
max_rev bigint;
_new_rows bigint;
begin
    select max(revision_number) into max_rev from public_api.document where pk = old.pk and document_type_id = old.document_type_id;

    if old.revision_number != max_rev then
        raise exception 'you can only delete the max revision number';
    end if;

    if max_rev > 0 then
        -- set the last revision as the latest
        raise notice 'setting last revision as latest';
        update public_api.document d set latest = true where d.pk = old.pk and document_type_id = old.document_type_id and revision_number = (max_rev - 1);
        get diagnostics _new_rows = ROW_COUNT;
        raise notice '% rows updated',_new_rows;
    end if;
    return old;
end;
$$ language plpgsql security definer;

drop trigger if exists before_delete_trigger on public_api.document;
create trigger before_delete_trigger before delete on public_api.document
for each row
execute procedure document_before_delete_trigger_f();


